{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#= Machine Learning Algorithms in Julia\n",
    "This notebook contains supervised and (some) unsupervised machine learning algorithms. \n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "knn (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function knn(X, Y, x, k)\n",
    "    n = size(X)[1]\n",
    "    dists_sq = [sum((X[i,:] .- x).^2) for i=1:n] #find distances of examples to x\n",
    "    nearest_neighbor_idxs = sortperm(dists_sq)[1:k] #find k-nearest neighbors\n",
    "    y_hat = sum(Y[nearest_neighbor_idxs, :], dims=1)/k #average k-nearest neighbors\n",
    "    return y_hat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softknn (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function softknn(X, Y, x, rho)\n",
    "    n = size(X)[1]\n",
    "    exp_weights = [exp(-sum((X[i,:] .- x).^2)/rho^2) for i=1:n]\n",
    "    w = exp_weights / sum(exp_weights) #find weights\n",
    "    y_hat = sum(w .* Y, dims=1) #weighted combination of Y\n",
    "    return y_hat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ridgeregressionconstfeature (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ridgeregressionconstfeature(X,Y,lambda)\n",
    "    n,d = size(X)\n",
    "    m = size(Y,2)\n",
    "    E = [zeros(d-1,1) I(d-1)]\n",
    "    A = [X; sqrt(lambda*n)*E]\n",
    "    B = [Y; zeros(d-1,m)]\n",
    "    theta = A\\B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tiltedLoss (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tiltedLoss(y_hat, y, tao)\n",
    "    if (y_hat - y) < 0\n",
    "        return -tao * (y_hat - y)\n",
    "    else\n",
    "        return (1-tao) * (y_hat - y)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regression_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux\n",
    "using LinearAlgebra\n",
    "\n",
    "function regression_fit(X, Y, l, r, lambda; numiters = 500)\n",
    "    #     Inputs:\n",
    "    #         X: input data\n",
    "    #         Y: output data\n",
    "    #         l: l(yhat, y)\n",
    "    #         r: r(theta)\n",
    "    #         lambda: regularization hyper-parameter\n",
    "    #         numiters (optional): number of iterations\n",
    "        \n",
    "        data = zip(eachrow(X), eachrow(Y))\n",
    "        n,d = size(X)\n",
    "        theta = ones(d)\n",
    "        predicty(x) = theta'*x\n",
    "        loss(x, y) = l(predicty(x), y[1])\n",
    "        cost(x,y) = loss(x,y) + lambda*r(theta)\n",
    "        risk() = sum((cost(d...) for d in data))/n\n",
    "        opt = Flux.ADAGrad()\n",
    "        losses = []\n",
    "        tracker() = push!(losses, risk())\n",
    "        Flux.@epochs numiters Flux.train!(cost, Flux.params(theta), data, opt, cb = Flux.throttle(tracker,10))\n",
    "        return theta\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnregression (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nnregression(X, Y, lambda; numiters=40)\n",
    "    d = size(X,2); m = size(Y,2)\n",
    "    model = Chain(\n",
    "        Dense(d, 10, relu),\n",
    "        Dense(10, 10, relu),\n",
    "        Dense(10, 10, relu),\n",
    "        Dense(10, m, identity))\n",
    "    data = zip(eachrow(X), eachrow(Y))\n",
    "    \n",
    "    normsquared(x) = sum(x.*x)\n",
    "    \n",
    "    reg() = sum([normsquared(m.W) for m in model])\n",
    "    predicty(x) = model(x)\n",
    "    \n",
    "    loss(x,y) = normsquared(predicty(x)-y)\n",
    "    cost(x,y) = loss(x,y) + lambda*reg()    \n",
    "    opt = Flux.Descent(0.001)\n",
    "    Flux.@epochs numiters Flux.train!(cost, Flux.params(model), data, opt)\n",
    "    return model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_logistic (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function multi_logistic(X, Y, reps)\n",
    "    # data sizes\n",
    "    n,d = size(X)\n",
    "    m = size(Y,2)\n",
    "    \n",
    "    # linear predictor parameter\n",
    "    theta = zeros(d,m)\n",
    "\n",
    "    # predictor\n",
    "    predicty(x) = theta'*x\n",
    "    margin(pi, pj, y) = (2*dot(pi-pj,y) + dot(pj,pj) - dot(pi,pi)) / (2*norm(pi-pj) + 1e-10)\n",
    "    multilogisticloss(yhat, y) = sum([exp(margin(r, y, yhat)) for r in reps])\n",
    "    loss(x,y) = multilogisticloss(predicty(x), y)\n",
    "\n",
    "    data = zip(eachrow(X), eachrow(Y))\n",
    "    opt = ADAMW()\n",
    "    Flux.@epochs 500 Flux.train!(loss, params(theta), data, opt)\n",
    "    return predicty, theta\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_means (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function square_I(x, theta)\n",
    "    return norm(x - theta)\n",
    "end\n",
    "\n",
    "function abslt_I(x, theta)\n",
    "    return norm(x - theta, 1)\n",
    "end\n",
    "\n",
    "function k_means(k, x, thetas)\n",
    "    min = norm(x - thetas[1,:])\n",
    "    for i = 2:k\n",
    "        if norm(x - thetas[i,:]) < min\n",
    "           min = norm(x - thetas[i,:])\n",
    "        end\n",
    "    end\n",
    "    return min\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "squ_r (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularizer functions\n",
    "function con_r(theta)\n",
    "    return mean(theta, 1)\n",
    "end\n",
    "\n",
    "function quad_r(theta)\n",
    "    return sum(theta.^2)\n",
    "end\n",
    "\n",
    "function abs_r(theta)\n",
    "    return sum(abs.(theta))\n",
    "end\n",
    "\n",
    "function squ_r(theta)\n",
    "    return sqrt(sum(abs.(theta)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "function l_quad(y_hat, y)\n",
    "    loss = (y_hat - y)^2\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function l_abs(y_hat, y)\n",
    "    loss = abs(y_hat - y)\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function l_hub1(y_hat, y)\n",
    "    r = y_hat - y\n",
    "    alpha = 0.5\n",
    "    loss = 1\n",
    "    if abs(r) <= alpha\n",
    "        loss = r^2 \n",
    "    else\n",
    "        loss = alpha * (2 * abs(r) - alpha)\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function l_hub2(y_hat, y)\n",
    "    r = y_hat - y\n",
    "    alpha = 1\n",
    "    loss = 1\n",
    "    if abs(r) <= alpha\n",
    "        loss = r^2 \n",
    "    else\n",
    "        loss = alpha * (2 * abs(r) - alpha)\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function l_hub3(y_hat, y)\n",
    "    r = y_hat - y\n",
    "    alpha = 2\n",
    "    loss = 1\n",
    "    if abs(r) <= alpha\n",
    "        loss = r^2 \n",
    "    else\n",
    "        loss = alpha * (2 * abs(r) - alpha)\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function l_loghub1(y_hat, y)\n",
    "    r = y_hat .- y\n",
    "    loss = 1\n",
    "    alpha = 0.5\n",
    "    if abs(r) <= alpha\n",
    "        loss = r^2 \n",
    "    else\n",
    "        loss = alpha * (1 - (2 * log(alpha)) + log(r^2))\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function l_loghub2(y_hat, y)\n",
    "    r = y_hat .- y\n",
    "    loss = 1\n",
    "    alpha = 1\n",
    "    if abs(r) <= alpha\n",
    "        loss = r^2 \n",
    "    else\n",
    "        loss = alpha * (1 - (2 * log(alpha)) + log(r^2))\n",
    "    end\n",
    "    return loss\n",
    "end\n",
    "\n",
    "function l_loghub3(y_hat, y)\n",
    "    r = y_hat .- y\n",
    "    loss = 1\n",
    "    alpha = 2\n",
    "    if abs(r) <= alpha\n",
    "        loss = r^2 \n",
    "    else\n",
    "        loss = alpha * (1 - (2 * log(alpha)) + log(r^2))\n",
    "    end\n",
    "    return loss\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
